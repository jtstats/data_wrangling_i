---
title: "Data Import"
author: "Jingyi"
date: "9/22/2019"
output: github_document
---

I downloaded the data and created a GitHub repo + local R project.

**How to move the datasets to my repo/directory?**
*Is https://help.github.com/en/articles/moving-a-file-to-a-new-location correct?*
**Follow the lecture, and just add the data files into the local R folder.**

```{r setup, include = FALSE}

# What does this mean?
knitr::opts_chunk$set(echo = TRUE)

# load the library
library(tidyverse)

```

## Load in a dataset

*I can use library(here) and here::here("file_I_want.csv") to find where my file is.*

**Never ever use setwd()**

```{r}

## reads in a dataset

# Load from a relative path.
# Question: What's the difference between read_csv and read.csv?
litters_data = read_csv(file = "./data/FAS_litters.csv")


## use janitor::clean_names() to clean up variable names after importing
## This will take the column names are and convert them to lower snake case.

names(litters_data)

litters_data = janitor::clean_names(litters_data)

names(litters_data)

# Question: Why my output are not italized?

```

**The package::function syntax lets you use a function from a package without loading the whole library.**
*Figure out what is conflicted package.*

***Leanring Assessment***

Make sure you are able to load the FAS_pups.csv dataset. Use both absolute and relative paths. Quit R Studio and move the directory containing your project, data, and R Markdown document. Repeat the previous data import process; do both absolute and relative paths still work?

```{r learning assessment #1}

# load from absolute path
FAS_pups_absolute = read_csv(file = "C://Users//Jingyi//Desktop//Columbia_University//Fall2019//P8105_Data_Science_I//Lecture In-Class Codes//Data_Wrangling_I//data_wrangling_i//Data//FAS_pups.csv")

# load from relative path
FAS_pups_relative = read.csv(file = "./data/FAS_pups.csv")

FAS_pups = janitor::clean_names(FAS_pups_relative)

```

Good Try!

##Looking at data

The first thing to do after importing the data (unless read_csv gives warnings) is to look at it. If there are unexpected results during data import, you’ll catch a lot of them here. In addition to printing the data, often time you can use View / view, str, head, and tail

```{r look at data}

#This will show the data
litters_data

#This will show the last 5 rows of data
tail(litters_data, 5)

```

Another tool to use can be skimr::skim.

```{r skimr::skim}

skimr::skim(litters_data)

```

*Call View/view in R console, because this function don't work well with RMD.*
This function will open a window (looks like excel) for you to view the dataset.

##Arguments to read_*

In the best case, the data are stored in the csv without any weirdness – there are no blank lines or columns, the first row is the variable name, missing values are stored in sensible ways. 

When this isn’t the case, arguments to read_csv are helpful. The ones I use most frequently are:

*col_names: usually TRUE. If FALSE, column names are X1, X1, … . You can also supply column names.
*na: string vector containing character expressions for missing values.
*skip: number of rows to skip before reading data.

For example, the call below will skip the first 50 lines of data and not assume the first row are variable names:

```{r read data skipping some lines}

litters_data = read_csv(file = "./data/FAS_litters.csv", skip = 10, col_names = FALSE)

head(litters_data)

```

These arguments generally work for other members of the read_* family of functions.

##Parsing Columns:

Skipped col_types

The read_* functions will attempt to guess the data type stored in each column; by default, these guesses are based on the first 1000 rows. The guesses are also usually pretty good. 

In some cases, though, you’ll want to give explicit column specifications. 

```{r parsing columns}

litters_data = read_csv(file = "./data/FAS_litters.csv", col_types = cols(
  Group = col_character(),
  `Little Number` = col_character(),
  `GD18 weight` = col_double(),
  `GD of Birth` = col_integer(),
  `Pups born alive` = col_integer(),
  `Pups dead @ birth` = col_integer(),
  `Pups survive` = col_integer()
))

tail(litters_data)

# short-hand

litters_data = read_csv(file = "./data/FAS_litters.csv",
  col_types = "ccddiiii"
)

litters_data

```


***Leanring Assessment***

Repeat the data import process above for the file FAS_pups.csv. Make sure the column names are reasonable, and take some quick looks at the dataset. What happens if your specifications for column parsing aren’t reasonable (e.g. character instead of double, or vice versa)?

```{r}

#load the data:

FAS_pups_relative = read.csv(file = "./data/FAS_pups.csv")

FAS_pups = janitor::clean_names(FAS_pups_relative)

# look at data

head(FAS_pups)

skimr::skim(FAS_pups)

# parse

pups_data = read_csv(file = "./data/FAS_pups.csv", col_types = "ciiiii")

# 

```

Non-csv plain text files (e.g. tab delimited files) can be handled using read_table. This is very similar to read_csv, but you have to specify a delimiter.

CSV format is great, but you’ll encounter a lot of Excel files too. Although you can export these to a csv, don’t – **use the readxl package instead!**

*The read_excel function in this package has many of the same arguments as read_csv, including col_names, na, skip, and col_types, and can be used in basically the same way.*

There is also a sheet option (useful when there are multiple sheets in the Excel file) and the range option (when you want to read in a specific data rectangle).

Lastly, in RStudio you can use File > Import Dataset > From Excel for a GUI interface. The code below illustrates read_excel.

```{r}

# read excel

library(readxl)

#Question: I ran into problem saying that my path does not exist
#Question solved b/c I put the wrong name; hence, of course incorrect path.

mlb11_data = read_excel("data/mlb11.xlsx", n_max = 20)

# Notice here that with ./data or not are both OK to read the file.

head(mlb11_data, 5)
```

The last tidyverse package for data import we’ll note is haven, which is used to import into R data files from SAS, Stata, and SPSS. 

```{r importing data from SAS}

library(haven)

pulse_data = read_sas("./data/public_pulse_data.sas7bdat")

head(pulse_data, 5)

```

You can read in data that isn’t coming as a flat file, but it’s beyond our current scope.



#Comparison with Base R

The functions in readr are relatively new, and can be used in place of base R’s read.csv, read.table, and so on. 

The base R versions tend to be slower (very noticeably for large datasets), and the default options can make less sense for modern datasets. 

Meanwhile, the readr functions export tibbles, and keep characters as characters (instead of converting to factors …).

**Learning Assesment #3:**
Import the FAS_pups.csv dataset using read.csv. Compare the class of this dataset to the one produced by read_csv. Try printing both in the console – what happens? After cleaning up the names, try accessing the Sex variable using S (e.g., pups_data$S). What happens?


```{r Learning Assessment #3}

# Use read.csv import dataset FAS_pups.csv

FAS_pups_dot = read.csv(file = "./data/FAS_pups.csv")

# Clean the data names 

FAS_pups_dot = janitor::clean_names(FAS_pups_dot)

# Use read_csv import dataset FAS_pups.cvs

FAS_pups_underscore = read_csv(file = "./data/FAS_pups.csv")

# Clean the data names

FAS_pups_underscore = janitor::clean_names(FAS_pups_underscore)

# to view the dataset, use view(filename) in console

#view(FAS_pups_dot)
#view(FAS_pups_underscore)

#FAS_pups_dot
#FAS_pups_underscore

#############
#Question: Why I can use S to accessing sex variable?
#############

#FAS_pups_dot$S
#FAS_pups_underscore$S

```

In short, read_csv produces tibbles which are very similar to the base R data frames produced by read.csv. However, **tibbles** have some features that can help prevent **mistakes and unwanted behavior**.

**Question: What mistakes????? What are tibbles?

Tibbles are just like dataframes, but slightly different.
They keep you from printing everything by accident.
They make you type complete variable names.



# Importing using File>Import

You can open many data files using RStudio’s drop-down menus.

To import an excel spreadsheet, for example, you can use File > Import Dataset > From Excel.

This allows several import options, previews the data, and shows the code necessary for importing. 
Importing in this way will load the data into your current session, but you’ll have to copy the import code to your RMarkdown file to ensure reproducibility.
 
This approach to importing data can be helpful when you’re getting started, but gaining proficiency with writing code directly will be helpful in the long term and is more consistent with the goals of the course.


# Export data

As a final point, you will sometimes need to export data after you have imported and cleaned it. The write_* functions in readr address this problem.
